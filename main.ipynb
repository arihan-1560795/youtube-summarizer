{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "# Download the YouTube Video\n",
    "#   Save it in a given channel -> video directory\n",
    "#   Download audio, video, segments, and metadata\n",
    "#   Whisper out transcript\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=kl0TrLkNUfw\n",
      "[youtube] kl0TrLkNUfw: Downloading webpage\n",
      "[youtube] kl0TrLkNUfw: Downloading ios player API JSON\n",
      "[youtube] kl0TrLkNUfw: Downloading android player API JSON\n",
      "[youtube] kl0TrLkNUfw: Downloading m3u8 information\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=kl0TrLkNUfw\n",
      "[youtube] kl0TrLkNUfw: Downloading webpage\n",
      "[youtube] kl0TrLkNUfw: Downloading ios player API JSON\n",
      "[youtube] kl0TrLkNUfw: Downloading android player API JSON\n",
      "[youtube] kl0TrLkNUfw: Downloading m3u8 information\n",
      "[info] kl0TrLkNUfw: Downloading 1 format(s): 140\n",
      "[download] audio.m4a has already been downloaded\n",
      "[download] 100% of   48.20MiB\n"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Path storing files pertaining to the video (e.g.- metadata, audio, transcript)\n",
    "file_path = ''\n",
    "video_id = ''\n",
    "\n",
    "# Function to read/ write JSON file. \n",
    "# It will process a file from/into Content/channel_id/video_id/file_name.json\n",
    "# It takes 4 parameters:\n",
    "#   cmd (str): Specifies the command to perform. 'w' for write and 'r' for read.\n",
    "#   video_metadata (dict): The metadata of the video. The channel_id and video_id will be extracted from this.\n",
    "#   file_name (str): The name of the JSON file to read or write\n",
    "#   obj_json: The dict we want to write (Blank if we're reading)\n",
    "def def_parse_json(cmd, video_metadata, file_name, obj_json=None):\n",
    "        # Extract relevant info from the metadata\n",
    "        channel_id = video_metadata.get('uploader_id', False) or video_metadata['channel_id']\n",
    "        video_id = video_metadata['id']\n",
    "\n",
    "        # Store the video metadata in a JSON file\n",
    "        full_directory = os.path.join('Content', channel_id, video_id)\n",
    "        if not os.path.exists(full_directory):\n",
    "                os.makedirs(full_directory)\n",
    "\n",
    "        # Join the directory and filename to get the full path\n",
    "        file_path = os.path.join(full_directory, file_name)\n",
    "\n",
    "        # Save the dictionary as a JSON object in the specified file\n",
    "        if cmd == 'w':\n",
    "                with open(file_path, 'w') as json_file:\n",
    "                        json.dump(obj_json, json_file, indent=4)\n",
    "        elif cmd == 'r':\n",
    "                with open(file_path, 'r') as json_file:\n",
    "                        return json.load(json_file)\n",
    "                \n",
    "# Function to download a YouTube video\n",
    "# It takes 1 parameter: the URL of the video to download\n",
    "# It will download and saves the video metadata, audio in the Content/channel_id/video_id directory\n",
    "# It will return the metadata dict\n",
    "def def_dl_youtube_video(video_url):\n",
    "\n",
    "    # Extract out the videoID (remove playlist or video timestamp/ other info)\n",
    "    video_url = 'https://www.youtube.com/watch?v=' + re.search(r'(?<=v=)[^&]+', video_url).group(0)\n",
    "\n",
    "\n",
    "\n",
    "    #=================== \n",
    "    # DOWNLOAD METADATA\n",
    "    # i.e.- upload date, uploader, video tags, chapters, etc.\n",
    "    #=================== \n",
    "\n",
    "    # TODO- Have a JSON file storing a list of all the videos we've downloaded, their dates, etc. in the parent directory\n",
    "    # TODO- Store the video w/ the ID in a dated folder; so 2023-12-31/video_id title/metadata.json\n",
    "    # Download metadata on the video; like the upload date, title, uploader, etc. \n",
    "    video_metadata = yt_dlp.YoutubeDL({}).extract_info(video_url, download=False)\n",
    "\n",
    "    # Save the metadata dictionary\n",
    "    def_parse_json('w', video_metadata, 'metadata.json', video_metadata)\n",
    "\n",
    "    #=================== \n",
    "    # DOWNLOAD AUDIO\n",
    "    #=================== \n",
    "\n",
    "    # TODO- Download sponsorblock segments\n",
    "    # TODO- Convert to MP3?\n",
    "    # TODO- Add metadata to MP3; like subtitles, creator, etc.\n",
    "    # TODO- Download subtitle data and save/ add it to the mp3\n",
    "    # TODO- Download video file itself?\n",
    "    # Specify we want the best audio quality, and to save it in the channel -> video directory\n",
    "    # Then, download the given URL\n",
    "    yt_dlp.\\\n",
    "        YoutubeDL({\n",
    "        'format': 'm4a/bestaudio',\n",
    "        'outtmpl': os.path.join(file_path, 'audio.m4a')\n",
    "\n",
    "    }).\\\n",
    "        download(video_url)\n",
    "\n",
    "    # Return the metadata dict to main\n",
    "    return video_metadata\n",
    "\n",
    "\n",
    "import whisper\n",
    "\n",
    "# Function to transcribe the audio of a video\n",
    "# It takes 1 parameter: the metadata dict of the video\n",
    "# We extract where the audio file is located from the metadata, and parse it\n",
    "# We return a dictionary representing the transcript; this is also saved as a JSON file in the Content/channel_id/video_id directory\n",
    "# TODO- Check if the transcript exists; if yes, abort\n",
    "def def_transcribe_audio(video_metadata):\n",
    "    model = whisper.load_model('small.en', device=\"cuda\")\n",
    "    video_transcript = model.transcribe(os.path.join(file_path, 'audio.m4a'), language='English')\n",
    "    def_parse_json('w', video_metadata, 'transcript.json', video_transcript)\n",
    "    return video_transcript\n",
    "\n",
    "\n",
    "import sponsorblock as sb\n",
    "def def_get_sponsor_segments(video_metadata):\n",
    "    client = sb.Client()\n",
    "    video_sponsor_segments = client.get_skip_segments(\"https://www.youtube.com/watch?v=\" + video_metadata['id'])\n",
    "\n",
    "    # Format the sponsor segments into a JSON object\n",
    "    video_sponsor_segments = {'segments': [({'category': x.category, 'start': x.start, 'end': x.end, 'duration': x.duration.seconds, 'action_type': x.action_type, 'uuid': x.uuid}) for x in video_sponsor_segments]}\n",
    "    def_parse_json('w', video_metadata, 'sponsor_segments.json', video_sponsor_segments)\n",
    "    return video_sponsor_segments\n",
    "\n",
    "video_metadata = def_dl_youtube_video('https://www.youtube.com/watch?v=kl0TrLkNUfw')\n",
    "video_transcript = def_transcribe_audio(video_metadata)\n",
    "video_sponsor_segments = def_get_sponsor_segments(video_metadata)\n",
    "\n",
    "# TODO- Split/ Group transcription by chapter; omit sponsor fragments\n",
    "# TODO- Download Model and try summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "upload_date = content_metadata['upload_date'][0:4] + '-' + content_metadata['upload_date'][4:6] + '-' + content_metadata['upload_date'][6:8]\n",
    "\n",
    "channel_id = content_metadata['channel_id']\n",
    "channel_name = content_metadata['channel']\n",
    "\n",
    "video_id = content_metadata['id']\n",
    "video_name = content_metadata['fulltitle']\n",
    "\n",
    "    \"duration\": 423,\n",
    "    \"view_count\": 70595,\n",
    "    \"categories\": array\n",
    "    \"tags\": array\n",
    "    \"chapters\": [\n",
    "        {\n",
    "            \"start_time\": 0.0,\n",
    "            \"title\": \"James discovers peer pressure\",\n",
    "            \"end_time\": 6.0\n",
    "        },\n",
    "uploader_id\n",
    "json = json.dumps(content_metadata)\n",
    "\n",
    "# open file for writing, \"w\" \n",
    "f = open(\"dict.json\",\"w\")\n",
    "\n",
    "# write json object to file\n",
    "f.write(json)\n",
    "\n",
    "# close file\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Downloads audio from a given YouTube Video URL\n",
    "\n",
    "# # URLS = 'https://www.youtube.com/watch?v=BaW_jenozKc'\n",
    "# # with YoutubeDL() as ydl:\n",
    "# #     ydl.download(URLS)\n",
    "\n",
    "# video_url = 'https://www.youtube.com/watch?v=kl0TrLkNUfw'\n",
    "# content_metadata = yt_dlp.YoutubeDL({}).extract_info(video_url, download=False)\n",
    "\n",
    "\n",
    "# import json\n",
    "# from pprint import pprint\n",
    "# pprint(json.dumps(content_metadata, sort_keys=True, indent=4, separators=(\",\", \": \")))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ffprobe\n",
      "  Downloading ffprobe-0.5.zip (3.5 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: ffprobe\n",
      "  Building wheel for ffprobe (pyproject.toml): started\n",
      "  Building wheel for ffprobe (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for ffprobe: filename=ffprobe-0.5-py3-none-any.whl size=3414 sha256=96c3882439135bcdc76b129df3d1acd0fb814e5b14ce37dcf13dc6ea44bdd41d\n",
      "  Stored in directory: c:\\users\\arihan\\appdata\\local\\pip\\cache\\wheels\\2c\\cb\\c1\\10daee0c3fad04c9d900006cd0f24bdd47afb74a5c1c085795\n",
      "Successfully built ffprobe\n",
      "Installing collected packages: ffprobe\n",
      "Successfully installed ffprobe-0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install ffprobe ffmpeg --upgrade\n",
    "pip install soundfile\n",
    "pip install torch\n",
    "pip install whisper\n",
    "pip install torch torchvision torchaudio\n",
    "# pip install yt-dlp --upgrade\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "pip install openai-whisper\n",
    "# cmd.exe -> nvcc --version \n",
    "\n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "\n",
    "pip install sponsorblock.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
